{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D(pool_size=2),\n",
    "        layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def call(self, output1, output2, target):\n",
    "        euclidean_distance = tf.reduce_mean(tf.square(output1 - output2), axis=-1, keepdims=True)\n",
    "        loss_contrastive = tf.reduce_mean((1 - target) * tf.square(euclidean_distance) +\n",
    "                                          (target) * tf.square(tf.maximum(self.margin - euclidean_distance, 0.0)))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the encoder using contrastive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "margin = 2.0\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "contrastive_loss = ContrastiveLoss(margin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss = 0.0\n",
    "    for (data, target) in train_dataset:\n",
    "        # Split the batch into two halves\n",
    "        half_batch = data.shape[0] // 2\n",
    "        data1, data2 = data[:half_batch], data[half_batch:]\n",
    "        target1, target2 = target[:half_batch], target[half_batch:]\n",
    "        # Generate the encodings for the two halves\n",
    "        encoding1 = encoder(data1)\n",
    "        encoding2 = encoder(data2)\n",
    "        # Compute the contrastive loss\n",
    "        target_contrastive = tf.cast(target1 == target2, dtype=tf.float32)\n",
    "        loss_contrastive = contrastive_loss(encoding1, encoding2, target_contrastive)\n",
    "        # Backpropagate and update the weights\n",
    "        gradients = tape.gradient(loss_contrastive, encoder.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, encoder.trainable_weights))\n",
    "        total_loss += loss_contrastive.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Epoch: {}, Loss: {:.4f}'.format(epoch, total_loss / (len(train_dataset))))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
